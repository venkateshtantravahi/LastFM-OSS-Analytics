name: lastfm_stack

x-airflow-common: &airflow-common
  image: apache/airflow:latest
  user: "${AIRFLOW_UID:-50000}:0"
  env_file:
    - ./.env
  environment:
    &airflow-common-env
    AIRFLOW__CORE__EXECUTOR: LocalExecutor
    AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: "true"
    AIRFLOW__CORE__LOAD_EXAMPLES: "false"
    AIRFLOW__LOGGING__LOGGING_LEVEL: INFO
     # Reuse the same Postgres credentials used by the postgres service
    AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: "postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}"
    AIRFLOW__CORE__FERNET_KEY: ""
    AIRFLOW__API_AUTH__JWT_SECRET: "sESAHF8CDg+C1blzPlOwgQ=="
    AIRFLOW__CORE__EXECUTION_API_SERVER_URL: http://airflow-api-server:8080/execution/
    AIRFLOW__API__BASE_URL: http://airflow-api-server:8080

    PYTHONPATH: /opt/airflow
    # Pin runtime deps installed inside the Airflow containers at start
    _PIP_ADDITIONAL_REQUIREMENTS: >
      boto3 pydantic pydantic-settings requests
      psycopg2-binary apache-airflow-providers-postgres
    # Pass-through for tasks (MinIO/Vault)
    S3_ENDPOINT: http://minio:9000
    S3_REGION: ${S3_REGION}
    S3_ADDRESSING_STYLE: path
    S3_BUCKET_RAW: ${S3_BUCKET_RAW}
    S3_BUCKET_CURATED: ${S3_BUCKET_CURATED}
    AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
    AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
    VAULT_ADDR: http://vault:8200
    VAULT_TOKEN: ${VAULT_DEV_ROOT_TOKEN_ID}
    VAULT_KV_MOUNT: ${VAULT_KV_MOUNT}
    LASTFM_API_KEY: ${LASTFM_API_KEY}
  volumes:
    - ../dags:/opt/airflow/dags
    - ../src:/opt/airflow/src
    - airflow_logs:/opt/airflow/logs

services:
  postgres:
    image: postgres:latest
    container_name: pg
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    ports: [ "5432:5432" ]
    volumes:
      - lastfm_pgdata:/var/lib/postgresql/data
      - ../docker/postgres/initdb.d:/docker-entrypoint-initdb.d
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U $$POSTGRES_USER" ]
      interval: 5s
      timeout: 3s
      retries: 10

  minio:
    image: quay.io/minio/minio:latest
    container_name: minio
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
    ports: [ "9000:9000", "9001:9001" ]
    volumes:
      - lastfm_minio:/data
    healthcheck:
      test: [ "CMD", "bash", "-c", "curl -fsS http://localhost:9000/minio/health/ready || exit 1" ]
      interval: 5s
      timeout: 3s
      retries: 20

  minio-mc:
    image: quay.io/minio/mc:latest
    container_name: minio_mc
    depends_on:
      minio:
        condition: service_healthy
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
      S3_BUCKET_RAW: ${S3_BUCKET_RAW}
      S3_BUCKET_CURATED: ${S3_BUCKET_CURATED}
    volumes:
      - ../docker/minio/create-buckets.sh:/usr/local/bin/create-buckets.sh:ro
    entrypoint: [ "/bin/sh", "-c" ]
    command: |
      /usr/local/bin/create-buckets.sh && tail -f /dev/null

  vault:
    image: hashicorp/vault:1.16
    container_name: vault
    cap_add: [ "IPC_LOCK" ]
    environment:
      VAULT_DEV_ROOT_TOKEN_ID: ${VAULT_DEV_ROOT_TOKEN_ID}
      VAULT_DEV_LISTEN_ADDRESS: 0.0.0.0:8200
      VAULT_API_ADDR: http://vault:8200
    ports: [ "8200:8200" ]
    command: [ "server", "-dev" ]
    volumes:
      - ../docker/vault/policies:/vault/policies:ro

  pgadmin:
    image: dpage/pgadmin4:8.12
    container_name: pg_admin
    environment:
      PGADMIN_DEFAULT_EMAIL: ${PGADMIN_EMAIL}
      PGADMIN_DEFAULT_PASSWORD: ${PGADMIN_PASSWORD}
    ports: [ "5050:80" ]
    depends_on: [ postgres ]

  airflow-api-server:
    <<: *airflow-common
    container_name: airflow-api-server
    command: api-server
    profiles: [ "airflow" ]
    ports: [ "8080:8080" ]
    depends_on: [ postgres ]
    environment:
      <<: *airflow-common-env
      AIRFLOW__API__HOST: 0.0.0.0
      AIRFLOW__API__PORT: 8080
    healthcheck:
      test: [ "CMD", "curl", "--fail", "http://localhost:8080/api/v2/monitor/health" ]
      interval: 10s
      timeout: 5s
      retries: 10

  airflow-scheduler:
    <<: *airflow-common
    container_name: airflow-scheduler
    command: scheduler
    profiles: [ "airflow" ]
    depends_on:
      airflow-api-server:
        condition: service_healthy
      postgres:
        condition: service_healthy
    environment:
      <<: *airflow-common-env
#      AIRFLOW__SDK__API_URL: http://airflow-api-server:8080
#      AIRFLOW__SDK__API_AUTH_BACKEND: airflow.sdk.api.auth.backend.default

  airflow-dag-processor:
    <<: *airflow-common
    container_name: airflow-dag-processor
    command: dag-processor
    profiles: [ "airflow" ]
    depends_on:
      airflow-api-server:
        condition: service_healthy
      postgres:
        condition: service_healthy
    environment:
      <<: *airflow-common-env
#      AIRFLOW__SDK__API_URL: http://airflow-api-server:8080
#      AIRFLOW__SDK__API_AUTH_BACKEND: airflow.sdk.api.auth.backend.default



  airflow-init:
    <<: *airflow-common
    container_name: airflow-init
    entrypoint: /bin/bash
    command: -c "airflow db migrate && airflow users create \
      --username ${AIRFLOW_ADMIN_USER:-admin} \
      --password ${AIRFLOW_ADMIN_PASSWORD:-admin} \
      --firstname Admin \
      --lastname User \
      --role Admin \
      --email ${AIRFLOW_ADMIN_EMAIL:-admin@example.com}"
    profiles: [ "airflow" ]


volumes:
  lastfm_pgdata: {}
  lastfm_minio: {}
  airflow_logs: {}
